# LangGraph Chatbot Service

AI-powered chatbot service for Remedi medicine exchange system using LangGraph.

## Features

- ğŸ¤– **Intelligent Chat Support**: Answer questions about medicine submission, points, vouchers
- ğŸ’¬ **Conversation Memory**: Maintains context across multiple messages
- ğŸ”— **FastAPI Integration**: Seamless connection with main backend
- ğŸš€ **Fast Inference**: Using Groq for quick responses (free tier available)

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend  â”‚â”€â”€â”€â”€â”€â–¶â”‚   FastAPI    â”‚â”€â”€â”€â”€â”€â–¶â”‚  LangGraph  â”‚
â”‚  (React)    â”‚      â”‚  (Backend)   â”‚      â”‚  (Chatbot)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚                       â”‚
                            â”‚                       â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                     â”‚  PostgreSQL  â”‚        â”‚   Groq API  â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Tech Stack

- **LangGraph**: Workflow orchestration
- **LangChain**: LLM framework
- **Groq**: Fast LLM inference (llama-3.1-8b-instant)
- **FastAPI**: REST API framework
- **PostgreSQL**: Database for user context

## Setup

### 1. Get Groq API Key

1. Visit https://console.groq.com/
2. Sign up for free account
3. Create API key
4. Copy to `.env` file

### 2. Environment Variables

```bash
# Required
GROQ_API_KEY=gsk_your_api_key_here
GROQ_MODEL=llama-3.1-8b-instant

# Optional (auto-configured in docker-compose)
FASTAPI_URL=http://fastapi:8000
POSTGRES_DSN=postgresql://admin:admin123@postgres:5432/medicine_recycling
```

### 3. Run with Docker

```bash
# From project root
docker-compose up langgraph --build
```

### 4. Test Chatbot

```bash
# Health check
curl http://localhost:8001/health

# Send chat message
curl -X POST http://localhost:8001/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "LÃ m sao Ä‘á»ƒ ná»™p thuá»‘c?",
    "user_id": "user-123",
    "session_id": "session-1"
  }'
```

## Project Structure

```
langgraph/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ main.py                 # FastAPI application
â”œâ”€â”€ workflow/
â”‚   â”œâ”€â”€ orchestrator.py         # LangGraph orchestrator
â”‚   â””â”€â”€ agents/
â”‚       â””â”€â”€ chat_support_agent.py  # Chat agent
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ state.py               # Agent state definitions
â”‚   â””â”€â”€ tools.py               # Helper tools
â”œâ”€â”€ factories/
â”‚   â””â”€â”€ llm_provider.py        # LLM factory (Groq, OpenAI, etc.)
â”œâ”€â”€ requirements.txt
â””â”€â”€ dockerfile
```

## Chatbot Capabilities

The chatbot can help users with:

âœ… **Medicine Submission**
- How to submit medicine
- Accepted medicine types
- Submission process

âœ… **Points & Rewards**
- How points are calculated
- Point balance inquiries
- Point redemption rules

âœ… **Vouchers**
- Available vouchers
- How to redeem
- Voucher terms

âœ… **Pharmacies**
- Partner pharmacy locations
- How to find nearby pharmacies
- Pharmacy information

âœ… **General Support**
- Account questions
- Technical issues
- System guidance

## API Endpoints

### POST `/chat`
Process chat message

**Request:**
```json
{
  "message": "LÃ m sao Ä‘á»ƒ ná»™p thuá»‘c?",
  "user_id": "uuid-here",
  "session_id": "session-1",
  "chat_history": [
    {"role": "user", "content": "..."},
    {"role": "assistant", "content": "..."}
  ]
}
```

**Response:**
```json
{
  "response": "Äá»ƒ ná»™p thuá»‘c, báº¡n cáº§n...",
  "session_id": "session-1",
  "status": "success"
}
```

### GET `/health`
Health check

**Response:**
```json
{
  "status": "healthy",
  "orchestrator": "initialized",
  "llm": "configured"
}
```

## Development

### Local Development

```bash
# Install dependencies
cd langgraph
pip install -r requirements.txt

# Set environment variables
export GROQ_API_KEY=your_key
export FASTAPI_URL=http://localhost:8000

# Run server
uvicorn app.main:app --reload --port 8001
```

### Testing

```python
# Python test
import httpx

response = httpx.post(
    "http://localhost:8001/chat",
    json={
        "message": "TÃ´i cÃ³ bao nhiÃªu Ä‘iá»ƒm?",
        "user_id": "user-123"
    }
)
print(response.json())
```

## Configuration

### LLM Models

You can switch between different LLM providers:

```python
# Groq (default - fast and free)
config = {
    "model_name": "llama-3.1-8b-instant",
    "api_key": os.getenv("GROQ_API_KEY")
}

# OpenAI
config = {
    "model_name": "gpt-4o-mini",
    "api_key": os.getenv("OPENAI_API_KEY")
}
```

### Memory & Context

- Conversations use `session_id` for memory
- Last 10 messages kept in context
- User context (points, submissions) fetched from database

## Troubleshooting

**Issue: Chatbot not responding**
- Check GROQ_API_KEY is set correctly
- Verify LangGraph service is running: `docker ps`
- Check logs: `docker logs 4de-langgraph-1`

**Issue: "LLM initialization failed"**
- Verify API key is valid
- Check internet connection to Groq API
- Try different model name

**Issue: Slow responses**
- Groq should be fast (~1-2s)
- Check network latency
- Consider reducing chat_history size

## Production Notes

- âœ… Add rate limiting
- âœ… Implement proper error handling
- âœ… Add monitoring/logging
- âœ… Use environment-specific configs
- âœ… Consider upgrading to paid LLM tier for better performance

## License

Part of Remedi Medicine Exchange System
